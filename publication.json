[

	{
		"CHI": "The ACM Conference on Human Factors in Computing Systems",
		"VIS": "IEEE Visualization and Visual Analytics Conference",
		"TVCG": "IEEE Transactions on Visualization and Computer Graphics",
		"CHI LBW": "CHI Conference Extended Abstracts on Human Factors in Computing Systems",
		"IUI": "The ACM Conference on Intelligent User Interfaces",
		"Ubicomp": "The ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies",
		"ACL": "Annual Meeting of the Association for Computational Linguistics",
		"EMNLP": "Empirical Methods in Natural Language Processing"
	}
	,
	{
		"separator": "2025" 
	}
		,
		{
		"title": "A Good Plan is Hard to Find: Aligning LLMs with Preferences is Misaligned with What Helps Users",
		"people": "Nishant Balepur, Matthew Shu, Yoo Yeon Sung, Seraphina Goldfarb-Tarrant, Shi Feng,  <text class = 'figx-name-style'>Fumeng Yang</text>, Rachel Rudinger, Jordan Lee Boyd‑Graber",
		"year": 2025,
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2025-plan.png",
		"paper_id": "2025-plan",
		"description": "We argue that aligning helpful LLMs needs feedback from real user interactions—not just preferences of what looks helpful.",
		"pdf": "https://arxiv.org/pdf/2509.18632",
		"video": "",
		"repo": "",
		"doi": "https://doi.org/10.48550/arXiv.2509.18632",
		"demo": "",
		"awards": "",
		"abbr": "EMNLP"
	}
	,
		{
		"title": "Self-Supervised Continuous Colormap Recovery from a Scalar Field Visualization without a Legend",
		"people": "Hongxu Liu, Xinyu Chen, Haoyang Zheng, Manyi Li, Zhenfan Liu, <text class = 'figx-name-style'>Fumeng Yang</text>, Yunhai Wang, Changhe Tu, Qiong Zeng",
		"year": 2025,
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2025-color.png",
		"paper_id": "2025-color",
		"description": "",
		"pdf": "https://arxiv.org/pdf/2507.20632",
		"video": "",
		"repo": "https://osf.io/gb2tx/?view_only=4d2a269b59bc4144b2806ec2d1a34e11",
		"doi": "",
		"demo": "",
		"awards": "",
		"abbr": "VIS"
	}
	,
	{
		"title": "Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas",
		"people": "Nishant Balepur, Vishakh Padmakumar,  <text class = 'figx-name-style'>Fumeng Yang</text>, Shi Feng, Rachel Rudinger, Jordan Lee Boyd‑Graber",
		"year": 2025,
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2025-persona.png",
		"paper_id": "2025-persona",
		"description": "We use abductive reasoning to infer user personas from preference data, so LLMs can deliver more personalized and inclusive responses",
		"pdf": "https://arxiv.org/abs/2501.11549",
		"video": "",
		"repo": "https://github.com/Pinafore/alignment-personalization",
		"doi": "https://doi.org/10.48550/arXiv.2501.11549",
		"demo": "",
		"awards": "",
		"abbr": "ACL"
	}
	,
	{
		"title": "Seeing Through the Overlap: The Impact of Color and Opacity on Depth Order Perception in Visualization",
		"people": "Zhiyuan Meng, Yunpeng Yang, Qiong Zeng<sup class='snowflake'>❊</sup>, Kecheng Lu, Lin Lu, Changehe Tu, <text class = 'figx-name-style'>Fumeng Yang</text><sup class='snowflake'>❊</sup>, Yunhai Wang",
		"year": 2025,
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2025-depth.png",
		"paper_id": "2025-depth",
		"description": "We comprehensively examine color, opacity, and their interaction for depth perception", 
		"pdf": "https://osf.io/wzuts",
		"video": "",
		"repo": "https://osf.io/n3jg8/",
		"doi": "https://doi.org/10.1145/3706598.3714070",
		"demo": "",
		"awards": "",
		"abbr": "CHI",
		"equal_contr": "<sup class='snowflake'>❊</sup>Equal mentorship; Zeng is the corresponding author & PI."
	}
	,
	{
		"separator": "2024" 
	}
	,
	{
		"title": "The Backstory to “Swaying the Public”: A Design Chronicle of Election Forecast Visualizations",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Mandi Cai, Chloe Mortenson, Hoda Fakhari, Ayse D. Lokmanoglu, Nicholas Diakopoulos, Erik C. Nisbet, Matthew Kay",
		"year": "2024",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2024-backstory.png",
		"paper_id": "2024-backstory",
		"description": "How we designed the election forecast visualizations for the 2022 governor elections",
		"pdf": "https://doi.org/10.31219/osf.io/927vy",
		"video": "https://youtu.be/6EDLSok9BB0",
		"repo": "https://www.doi.org/10.17605/osf.io/ygq2v",
		"doi": "https://doi.org/10.1109/TVCG.2024.3456366",
		"demo": "",
		"awards": "",
		"abbr": "VIS"
	},
	{
		"title": "Promises and Pitfalls: Using Large Language Models to Generate Visualization Items",
		"people": "Yuan (Charles) Cui, Lily W. Ge, Yiren Ding, Lane Harrison,  <text class = 'figx-name-style'>Fumeng Yang</text>, Matthew Kay",
		"year": "2024",
		"video": null,
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2024-vila.png",
		"pdf": "https://osf.io/au3er",
		"paper_id": "2024-vila",
		"description": "We designed a vila pipeline that uses LLM to generate high-quality visualization items across multiple cognitive levels",
		"repo": "https://osf.io/ysrhq/",
		"abbr": "VIS",
		"doi": "https://doi.org/10.1109/TVCG.2024.3456309",
		"awards": null
	},
	{
		"title": "In Dice We Trust: Uncertainty Displays for Maintaining Trust in Election Forecasts Over Time",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Chloe Mortenson, Erik C. Nisbet, Nicholas Diakopoulos, Matthew Kay",
		"year": "2024",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2024-dice.png",
		"paper_id": "2024-dice",
		"description": "We provide design recommendations for conveying U.S. presidential election forecasts",
		"pdf": "https://osf.io/preprints/osf/9x4nr",
		"video": "https://youtu.be/1pE5yGXHpGU",
		"repo": "https://osf.io/923e7/",
		"doi": "https://doi.org/10.1145/3613904.3642371",
		"demo": "https://forecasts.cs.northwestern.edu/2023-hypothetical-elections/?PROLIFIC_PID=use_testing_or_a_very_long_string",
		"awards": "Best Paper Award (top 1%)",
		"abbr": "CHI"
	},
	{
		"title": "A Comparative Study on Visualizations of Scheduled Event Sequences: Gantt, Extended Gantt, and Stringline Charts",
		"people": "Junxiu Tang, <text class = 'figx-name-style'>Fumeng Yang</text>, Jiang Wu, Yifang Wang, Jiayi Zhou, Xiwen Cai, Lingyun Yu, Yingcai Wu",
		"year": "2024",
		"video": "",
		"paper_id": "2024-marey",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2024-marey2.png",
		"pdf": "https://osf.io/qdpzm/",
		"description": "We evaluated  the  effectiveness  of  Gantt  charts,  extended  Gantt  charts, and  stringline  charts  for  visualizing  fixed-order  event  sequence data",
		"repo": "https://osf.io/qdpzm/",
		"doi": "https://doi.org/10.1109/TVCG.2024.3358919",
		"awards": "",
		"abbr": "TVCG"
	},
	{
		"separator": "2023" 
	   }
	   ,
	{
		"title": "Swaying the Public? Impacts of Election Forecast Visualizations on Emotion, Trust, and Intention in the 2022 U.S. Midterms",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Mandi Cai, Chloe Mortenson, Hoda Fakhari, Ayse D. Lokmanoglu, Jessica Hullman, Steven Franconeri, Nicholas Diakopoulos, Erik C. Nisbet, Matthew Kay",
		"year": "2023",
		"video": "https://youtu.be/nm0BsaslyZs?si=1IOgCBsJLgrRpSdg",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2023-midterm.png",
		"paper_id": "2023-midterm",
		"pdf": "https://osf.io/qpyna/",
		"demo": "https://forecasts.cs.northwestern.edu/2022-governors-elections",
		"description": "We conducted a longitudinal study and measured the impacts of visual designs in real eletions",
		"repo": "https://osf.io/ajq8f/",
		"doi": "https://doi.org/10.17605/OSF.IO/AJQ8F",
		"awards": "Best Paper Award (top 1%)",
		"abbr": "VIS"
	},
	{
		"title": "Adaptive Assessment of Visualization Literacy",
		"people": "Yuan (Charles) Cui, Lily W. Ge, Yiren Ding, <text class = 'figx-name-style'>Fumeng Yang</text>, Lane Harrison, Matthew Kay",
		"year": "2023",
		"video": null,
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2023-cat.png",
		"pdf": "https://osf.io/a6258/",
		"paper_id": "2023-cat",
		"description": "We developed two computerized adaptive tests (CATs) for visualization literacy, which measure the same set of skills as their original versions in half the number of questions",
		"repo": "https://osf.io/a6258/",
		"abbr": "VIS",
		"doi": "https://doi.org/10.1109/TVCG.2023.3327165",
		"awards": null
	},
	{
		"title": "Subjective Probability Correction for Uncertainty Representations",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Maryam Hedayati, Matthew Kay",
		"year": "2023",
		"video": "",
		"paper_id": "2023-bias-correction",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2023-bias-correction2.png",
		"pdf": "https://osf.io/z6fcw/",
		"description": "We developed a cognitive debiasing technique that adjusts a forecast distribution based on a model of subjective probability",
		"abbr": "CHI",
		"repo": "https://doi.org/10.17605/OSF.IO/KCWXM",
		"doi": "https://doi.org/10.1145/3544548.3580998",
		"awards": "Honorable Mention Award (top 5%)"
	},
	{
		"title": "How Can Deep Neural Networks Aid Visualization Perception Research?",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Yuxin Ma, Lane Harrison, James Tompkin, David H. Laidlaw",
		"year": "2023",
		"video": "https://youtu.be/48xtQbnJDI8",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2023-dnn.png",
		"paper_id": "2023-dnn",
		"abbr": "CHI",
		"pdf": "https://osf.io/u3n5f/",
		"description": "This paper provides insights from three perspectives—prediction, generalization, and interpretation—via training and analyzing deep convolutional neural networks on human correlation judgments in scatterplots",
		"repo": "https://doi.org/10.17605/osf.io/exa8m",
		"doi": "https://doi.org/10.1145/3544548.3581111",
		"awards": ""
	},
	{
		"separator": "2022 and earlier" 
	   }
	   ,
	{
		"title": "Visual Cue Effects on a Classification Accuracy Estimation Task in Immersive Scatterplots",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, James Tompkin, Lane Harrison, David H. Laidlaw",
		"year": "2022",
		"video": "https://youtu.be/XGuV3x4Ud2A",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2022-vrsd.png",
		"paper_id": "2022-vrsd",
		"abbr": "TVCG",
		"pdf": "https://osf.io/wkyqe",
		"description": "It seems that most visual cues may not strongly affect perception in immersive analytics unless they change people's mental model about data",
		"repo": "https://doi.org/10.17605/OSF.IO/PKUVZ",
		"doi": "https://doi.org/10.1109/TVCG.2022.3192364",
		"awards": ""
	},
	{
		"title": "Rethinking the Ranks of Visual Channels",
		"people": "Caitlyn M. McColeman<sup class='snowflake'>❊</sup>, <text class = 'figx-name-style'>Fumeng Yang</text><sup class='snowflake'>❊</sup>, Timothy F. Brady, Steven Franconeri",
		"year": "2021",
		"video": "",
		"abbr": "VIS",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2021-rethinking.png",
		"paper_id": "2021-rethinking",
		"pdf": "https://osf.io/n7kxu/",
		"description": "The conventional ranking did not hold, even for only 2 marks, and the new probabilistic ranking was highly inconsistent for different numbers of marks",
		"repo": "https://doi.org/10.17605/OSF.IO/3E2QT",
		"doi": "https://doi.org/10.1109/TVCG.2021.3114684",
		"equal_contr": "<sup class='snowflake'>❊</sup>Equal contributions",
		"awards": "Honorable Mention Award (top 5%)"
	},
	{
		"title": "Revealing Perceptual Proxies with Adversarial Examples",
		"people": "Brian D. Ondov, <text class = 'figx-name-style'>Fumeng Yang</text>, Matthew Kay, Niklas Elmqvist, Steven Franconeri",
		"year": "2020",
		"video": "https://youtu.be/B8Kum6RehbE?t=7641",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2020-proxy.png",
		"pdf": "https://osf.io/83t4b/",
		"paper_id": "2020-proxy",
		"description": "We give evidence of specific visual proxies for extracting mean and range from bar charts",
		"abbr": "VIS",
		"repo": "https://osf.io/2re7b/",
		"doi": "https://doi.org/10.1109/TVCG.2020.3030429"
	},
	{
		"title": "A Virtual Reality Memory Palace Variant Aids Knowledge Retrieval from Scholarly Articles",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Jing Qian, Johannes Novotny, David Badre, Cullen D. Jackson, David H. Laidlaw  ",
		"year": "2020",
		"abbr": "TVCG",
		"video": "https://www.youtube.com/watch?v=-vdmbHn6Lhc",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2020-mp.png",
		"pdf": "https://osf.io/259zy/",
		"paper_id": "2020-mp",
		"description": "We show that virtual  reality  techniques  can  supporthigh-level cognitive tasks at least as well as traditionalmedia such as screen",
		"doi": "https://doi.org/10.1109/TVCG.2020.3009003",
		"repo": "https://osf.io/2v8ae/"
	},
	{
		"title": "How Do Visual Explanations Foster End Users' Appropriate Trust in Machine Learning?",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Zhuanyi (Yi) Huang, Jean Scholtz, Dustin L. Arendt",
		"year": "2020",
		"abbr": "IUI",
		"video": "https://www.youtube.com/watch?v=GLtDANA8XFQ",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2020-ml-trust.png",
		"paper_id": "2020-ml-trust",
		"pdf": "https://osf.io/s9q8t/",
		"description": "All our visual explanations reduce overtrust and undertrust, thereby fostering appropriate trust",
		"awards": "Honorable Mention Award (top 1%)",
		"doi": "https://doi.org/10.1145/3377325.3377480",
		"repo": "https://osf.io/rghcz/"
	},
	{
		"title": "Portalware: A Smartphone-Wearable Dual-Display System for Expanding the Free-Hand Interaction Region in Augmented Reality",
		"people": "Jing Qian, Meredith Young-Ng, Xiangyu Li, Angel Cheung, <text class = 'figx-name-style'>Fumeng Yang</text>, Jeff Huang",
		"year": "2020",
		"abbr": "CHI LBW",
		"video": null,
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2020-portalware.jpg",
		"paper_id": "2020-portalware",
		"pdf": "https://dl.acm.org/doi/abs/10.1145/3334480.3383079",
		"doi": "https://dx.doi.org/10.1145/3334480.3383079"
	},
	{
		"title": "Remotion: A Motion-Based Capture and Replay Platform of Mobile Device Interaction",
		"people": "Jing Qian, Arielle Chapin, Alexandra Papoutsaki, <text class = 'figx-name-style'>Fumeng Yang</text>, Klaas Nelissen, Jeff Huang",
		"year": "2018",
		"video": null,
		"abbr": "Ubicomp",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2018-remotion.jpg",
		"paper_id": "2018-remotion",
		"link": "http://remotion.cs.brown.edu",
		"pdf": "projs/remotion/remotion.pdf",
		"doi": "https://doi.org/10.1145/3214280",
		"description": "We use mobile sensoring and physical visualizations to replay user interactions"
	},
	{
		"title": "Correlation Judgment and Visualization Features",
		"people": "<text class = 'figx-name-style'>Fumeng Yang</text>, Lane Harrison, Ronald A. Rensink, Steven Franconeri, Remco Chang",
		"year": "2018",
		"video": null,
		"abbr": "TVCG",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2018-vf.png",
		"paper_id": "2018-vf",
		"pdf": "https://osf.io/9yb2a/",
		"repo": "https://osf.io/ew8hv/",
		"doi": "https://doi.org/10.1109/TVCG.2018.2810918",
		"description": "We build perceptual models for correlation perception in scatterplots"
	},
	{
		"title": "Ranking Visualizations of Correlation Using Weber's Law",
		"people": "Lane Harrison, <text class = 'figx-name-style'>Fumeng Yang</text>, Steven Franconeri, Remco Chang",
		"year": "2014",
		"video": null,
		"abbr": "VIS",
		"paper_id": "2014-weber",
		"thumbnail": "https://raw.githubusercontent.com/fig-x/fig-x-data/main/publication/2014-weber.png",
		"pdf": "http://valt.cs.tufts.edu/pdf/harrison2014ranking.pdf",
		"repo": "https://github.com/TuftsVALT/ranking-correlation",
		"doi": "https://doi.org/10.1109/TVCG.2014.2346979",
		"description": "We model the perception of correlation in several visualizations using Weber’s law"
	}
]
